{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective:\n",
    "- Provide an example of creating alt-text descriptions for images using aws bedrock -- specifically Claude Sonnet 3.5 v1.\n",
    "\n",
    "What are we using?\n",
    "- Python\n",
    "- AWS\n",
    "-- Amazon Bedrock\n",
    "-- IAM\n",
    "-- Boto3 (AWS SDK for Python)\n",
    "- Claude 3 Sonnet\n",
    "\n",
    "What do you need to install?\n",
    "- python-dotenv\n",
    "-- to load our creds\n",
    "- boto3\n",
    "- pybase64\n",
    "- pillow\n",
    "-- images sent to the llm need to be less than 5 mb. Use the PIL to scale all images to 300 dpi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by installing dependencies\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install python-dotenv\n",
    "!{sys.executable} -m pip install boto3\n",
    "!{sys.executable} -m pip install pybase64\n",
    "!{sys.executable} -m pip install pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import boto3\n",
    "import json\n",
    "from PIL import Image\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment variables\n",
    "# we use override=True to ensure that the values are refreshed if we edit them on the external \n",
    "# configuration file since there seems to be a bug with the Jupyter extension for VS Code where \n",
    "# it doesn't reload them even if you close and open the notebook again\n",
    "dotenv.load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set our credentials from the environment values loaded form the .env file\n",
    "AWS_ACCESS_KEY_ID = os.environ.get('AWS_ACCESS_KEY_ID')\n",
    "AWS_SECRET_ACCESS_KEY = os.environ.get('AWS_SECRET_ACCESS_KEY')\n",
    "AWS_REGION = os.environ.get('AWS_REGION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a bedrock client using boto3 (AWS' official Python SDK)\n",
    "bedrock_runtime_client = boto3.client(\n",
    "    'bedrock-runtime',\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name=AWS_REGION\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the model -- you need to retrieve the model ID.  This can be retreived from the Bedrock interface or via the AWS CLI.  \n",
    "\n",
    "**Using the Bedrock interface**\n",
    "+ Navigate to Amazon Bedrock\n",
    "+ In the foundational models, select Claude\n",
    "+ Select the Claude Sonnet 3.5 v1 model.  You will see the Model Id and Model ARN.  You need the model id.\n",
    "\n",
    "**Using the AWS CLI**\n",
    "+ aws bedrock list-foundational-models --by-provider anthropic\n",
    "\n",
    "[AWS Documentation: list-foundational-models](https://docs.aws.amazon.com/cli/latest/reference/bedrock/list-foundation-models.html)\n",
    "\n",
    "Example Response: \n",
    "\n",
    "[cloudshell-user@ip-10-138-4-48 ~]$ aws bedrock  list-foundation-models --by-provider anthropic  \n",
    "  \n",
    "    {  \n",
    "        \"modelSummaries\": [          \n",
    "            {  \n",
    "                \"modelArn\": \"arn:aws:bedrock:us-west-2::foundation-model/anthropic.claude-instant-v1:2:100k\",  \n",
    "                \"modelId\": \"anthropic.claude-instant-v1:2:100k\",  \n",
    "                \"modelName\": \"Claude Instant\",  \n",
    "                \"providerName\": \"Anthropic\",  \n",
    "                \"inputModalities\": [  \n",
    "                    \"TEXT\"  \n",
    "                ],  \n",
    "                \"outputModalities\": [  \n",
    "                    \"TEXT\"  \n",
    "                ],  \n",
    "                \"responseStreamingSupported\": true,  \n",
    "                \"customizationsSupported\": [],  \n",
    "                \"inferenceTypesSupported\": [  \n",
    "                    \"PROVISIONED\"  \n",
    "                ],  \n",
    "                \"modelLifecycle\": {  \n",
    "                    \"status\": \"ACTIVE\"  \n",
    "                }   \n",
    "            }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the model id\n",
    "model_id = \"anthropic.claude-3-5-sonnet-20240620-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a 5 MB limit on the image data buffer.  This means\n",
    "# that we need to make sure images are scaled.  \n",
    "\n",
    "# So, check the image size.  If the image is larger that 4.5 mbs, \n",
    "# scale it.\n",
    "filename = 'SPEC-PA-56-0024-Box17-Folder22_0031.tif'\n",
    "image_path = 'data/' + filename\n",
    "tmp_image = 'data/' + filename + '.png'\n",
    "\n",
    "image_size = os.path.getsize(image_path)\n",
    "\n",
    "if image_size < 4500000:\n",
    "    tmp_image = image_path\n",
    "else:    \n",
    "    base_width = 800\n",
    "    img = Image.open(image_path)\n",
    "    wpercent = (base_width / float(img.size[0]))\n",
    "    hsize = int((float(img.size[1]) * float(wpercent)))\n",
    "    img = img.resize((base_width, hsize), Image.Resampling.LANCZOS)\n",
    "    img.save(tmp_image)\n",
    "\n",
    "with open(tmp_image, 'rb') as image_file:\n",
    "    encoded_image = base64.b64encode(image_file.read()).decode()\n",
    "\n",
    "if tmp_image != image_path:\n",
    "    # delete temp file\n",
    "    os.remove(tmp_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Generate WCAG 2.1-compliant alt text and longer description for a stand-alone image. The output must be in strict JSON format as follows:\" _\n",
    "    {\\\"image\\\":  {\\\"alt\\\": \\\"Alternative text\\\",\\\"desc\\\": \\\"Long-description\\\"}}\n",
    "    Follow these guidelines to create appropriate and effective alt text:\n",
    "    1. Image Description:\n",
    "       - Describe the key elements of the image, including objects, people, scenes, and any visible text.\n",
    "       - Consider the image’s role within the PDF. What information or function does it provide?\n",
    "    2. WCAG 2.1 Compliance:\n",
    "       a) Text in Image:\n",
    "          - If duplicated nearby, use empty alt text: alt=“”\n",
    "          - For functional text (e.g., icons), describe the function\n",
    "          - Otherwise, include the exact text\n",
    "       b) Functional Images:\n",
    "          - For links/buttons, describe the action/destination\n",
    "       c) Informative Images:\n",
    "          - Provide a concise description of essential information\n",
    "          - For complex images, summarize key data or direct to full information\n",
    "       d) Decorative Images:\n",
    "          - Use empty alt text: alt=“”\n",
    "    3. Output Guidelines:\n",
    "       - Keep alt text short, clear, and relevant and no longer than 25 words\n",
    "       - Keep long description clear and relevant and no longer than 250 words\n",
    "       - Ensure it enhances accessibility for assistive technology users\n",
    "    Remember:\n",
    "    - Provide only the JSON output with no additional explanation\n",
    "    - Do not use unnecessary phrases like “Certainly!” or “Here’s the alt text:”\n",
    "    - If you’re unsure about specific details, focus on describing what you can clearly determine from the context provided\n",
    "    Now, based on the information given and these guidelines, generate the appropriate alt text in the required JSON format.\"\"\"\n",
    "\n",
    "payload = {\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"image\",\n",
    "                    \"source\": {\n",
    "                        \"type\": \"base64\",\n",
    "                        \"media_type\": \"image/jpeg\",\n",
    "                        \"data\": encoded_image\n",
    "                    }\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ],\n",
    "    \"max_tokens\": 10000,\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each model has a different template for interaction.  \n",
    "\n",
    "For Claude 3 models, the template is the following:\n",
    "\n",
    "    payload = {  \n",
    "        \"messages\": [  \n",
    "            {  \n",
    "                \"role\": \"\",  \n",
    "                \"content\": []  \n",
    "            }  \n",
    "        ],  \n",
    "        \"anthropic_version\": \"\"  \n",
    "    }  \n",
    "\n",
    "\n",
    "Messages is an array of json objects which must contain at least one item following. Each message must strictly follow the schema and declare:\n",
    "- role: this can be either user, or system. \n",
    "- content: this is also an array as you can send multiple content items in one API request to Claude. At minimum you will have one.\n",
    "\n",
    "https://community.aws/content/2dfToY7frDS4y8LsTkntgBzORju/hands-on?lang=en\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we first need to load our image and convert it to base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we're ready to invoke the model!\n",
    "response = bedrock_runtime_client.invoke_model(\n",
    "    modelId=model_id,\n",
    "    contentType=\"application/json\",\n",
    "    body=json.dumps(payload)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to read the response. It comes back as a stream of bytes \n",
    "# so if we want to display the response in one go we need to read the full stream first\n",
    "# then convert it to a string as json and load it as a dictionary \n",
    "# so we can access the field containing the content without all the metadata noise\n",
    "output_binary = response[\"body\"].read()\n",
    "output_json = json.loads(output_binary)\n",
    "output = output_json[\"content\"][0][\"text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
